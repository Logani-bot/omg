#!/usr/bin/env python3
"""
OMG Phase 1.5 — DEBUG CSV batch generator (updated)

Changes in this version:
- ❌ Removed any built-in "top30" / auto-universe selection.
- ✅ Load symbols from an external universe list (CSV/TXT) generated by universe_selector.
- ✅ For every symbol in that list, create a debug CSV under ./data/<symbol>_debug.csv
- ✅ Keep single-symbol debug available for quick tests.

Usage examples:
  # Batch: read universe file and generate ALL debug CSVs into ./data
  python -u omg2.py --universe-file ./state/universe/top_list_coin.csv --limit-days 180

  # Single symbol quick run (still supported)
  python -u omg2.py --debug ADA --limit-days 2000

Universe file format:
- CSV or TXT. The script will try the following columns/fields in order:
  ['symbol','ticker','code']
- If it's a TXT, each non-empty line is treated as a symbol.
- Symbols can be plain (e.g., ADA, SUI) or full (e.g., ADAUSDT). Plain symbols
  will be normalized to <SYMBOL>USDT for Binance spot.

Output:
- ./data/<lower_symbol>_debug.csv (e.g., ./data/ada_debug.csv)
"""
from __future__ import annotations
import argparse
import csv
import datetime as dt
import json
from pathlib import Path
from typing import Iterable, List, Optional
import time

import requests

# =========================
# Config
# =========================
DATA_DIR = Path("./data")
DATA_DIR.mkdir(parents=True, exist_ok=True)

BINANCE_API = "https://api.binance.com"  # public
KLINES_EP = "/api/v3/klines"            # /api/v3/klines?symbol=BTCUSDT&interval=1d&limit=1000
EXINFO_EP  = "/api/v3/exchangeInfo"      # /api/v3/exchangeInfo?symbol=BTCUSDT

# accepted quote assets to probe (priority order)
QUOTES = ["USDT", "FDUSD", "BUSD", "TUSD", "USDC", "BTC", "BNB"]

# =========================
# Helpers
# =========================

_pair_status_cache: dict[str, Optional[str]] = {}


def binance_pair_status(symbol_pair: str) -> Optional[str]:
    """Return Binance status string (e.g., 'TRADING') or None if not found."""
    sp = symbol_pair.strip().upper()
    if sp in _pair_status_cache:
        return _pair_status_cache[sp]
    try:
        r = requests.get(BINANCE_API + EXINFO_EP, params={"symbol": sp}, timeout=10)
        if r.status_code == 400:
            _pair_status_cache[sp] = None
            return None
        r.raise_for_status()
        data = r.json()
        syms = data.get("symbols", [])
        if not syms:
            _pair_status_cache[sp] = None
            return None
        status = syms[0].get("status")
        _pair_status_cache[sp] = status
        return status
    except Exception:
        _pair_status_cache[sp] = None
        return None


def resolve_pair(base_or_pair: str) -> Optional[str]:
    """Resolve a base symbol (e.g., 'ADA') to an available Binance pair.
    If already a pair, validate it. Probe quotes in QUOTES order.
    Returns exact pair string or None if not found.
    """
    s = base_or_pair.strip().upper()
    # reject obvious quote-only inputs
    if s in QUOTES:
        return None
    # already a pair?
    if any(s.endswith(q) for q in QUOTES):
        return s if (binance_pair_status(s) == "TRADING") else None
    # try quotes in order
    for q in QUOTES:
        probe = f"{s}{q}"
        st = binance_pair_status(probe)
        if st == "TRADING":
            return probe
    return None

def norm_to_binance_spot(symbol: str) -> str:
    s = symbol.strip().upper()
    return s if any(s.endswith(q) for q in QUOTES) else f"{s}USDT"


def stem_from_symbol(symbol: str) -> str:
    s = symbol.strip().upper()
    for q in QUOTES:
        if s.endswith(q):
            return s[: -len(q)].lower()
    return s.lower()


def fetch_binance_1d_ohlc(symbol_pair: str, limit_days: int = 180) -> List[dict]:
    """Fetch daily klines for an exact Binance symbol pair (e.g., ADAUSDT)."""
    sym = symbol_pair.strip().upper()
    remaining = max(1, int(limit_days))
    rows: List[dict] = []
    end_time_ms: Optional[int] = None

    while remaining > 0:
        batch = min(remaining, 1000)
        params = {
            "symbol": sym,
            "interval": "1d",
            "limit": batch,
        }
        if end_time_ms:
            params["endTime"] = end_time_ms
        r = requests.get(BINANCE_API + KLINES_EP, params=params, timeout=15)
        r.raise_for_status()
        kl = r.json()
        if not isinstance(kl, list) or not kl:
            break
        part = [
            {
                "openTime": k[0],
                "open": float(k[1]),
                "high": float(k[2]),
                "low": float(k[3]),
                "close": float(k[4]),
                "volume": float(k[5]),
                "closeTime": k[6],
            }
            for k in kl
        ]
        rows.extend(part)
        remaining -= len(part)
        first_open = kl[0][0]
        end_time_ms = int(first_open) - 1
        time.sleep(0.1)
    rows.sort(key=lambda x: x["openTime"]) 
    return rows[-limit_days:] if len(rows) > limit_days else rows


def ts_to_date(ms: int) -> str:
    return dt.datetime.fromtimestamp(ms/1000, tz=dt.timezone.utc).strftime("%Y-%m-%d")


# =========================
# OMG 1.5 debug core (single symbol)
# =========================

def debug_cycle_for_symbol(symbol_pair: str, limit_days: int = 180) -> Path:
    """Track cycle states and save CSV for one *validated* pair into ./data."""
    ohlc = fetch_binance_1d_ohlc(symbol_pair, limit_days=limit_days)
    if not ohlc:
        raise RuntimeError(f"No OHLC fetched for {symbol_pair}")

    L: Optional[float] = None
    H: Optional[float] = None
    mode = "none"

    out_path = DATA_DIR / f"{stem_from_symbol(symbol_pair)}_debug.csv"
    with out_path.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["date","open","high","low","close","mode","L","H","cand_H","thr56","event"])  
        for row in ohlc:
            p = float(row["high"]) if row["high"] is not None else None
            lo = float(row["low"])  if row["low"]  is not None else None
            date = ts_to_date(int(row["closeTime"]))
            event = ""
            cand_H = None
            thr56 = None

            if mode == "high":
                cand_H = p if (H is None or (p is not None and p > H)) else H
                thr56 = None if cand_H is None else round(cand_H * 0.56, 10)
                if cand_H is not None and lo is not None and lo <= cand_H * 0.56:
                    mode = "wait"; H = cand_H; L = lo; event = "TO_WAIT_-44%"
                else:
                    H = cand_H
            else:
                if lo is not None and (L is None or lo < L):
                    L = lo
                if mode == "wait":
                    if L is not None and p is not None and p >= L * 1.985:
                        H = p; mode = "high"; event = "RESTART_+98.5%_H=p"
                else:
                    if L is not None and p is not None and p >= L * 1.985:
                        H = p; mode = "high"; event = "START_+98.5%_H=p"
                    elif H is not None and p is not None and p > H:
                        H = p; mode = "high"; event = "START_BREAK_PREV_H_H=p"

            w.writerow([
                date,
                row["open"], row["high"], row["low"], row["close"],
                mode,
                (None if L is None else round(L, 10)),
                (None if H is None else round(H, 10)),
                (None if cand_H is None else round(cand_H, 10)),
                (None if thr56 is None else thr56),
                event,
            ])
    return out_path


# =========================
# Universe loading
# =========================

def is_probable_symbol(token: str) -> bool:
    """Heuristic: looks like a coin base symbol.
    - 2 ~ 12 uppercase letters (A-Z)
    - must not be digits-only, must not start with a digit
    - may optionally end with 'USDT' (we strip later)
    """
    if not token:
        return False
    s = token.strip().upper()
    if s.endswith("USDT"):
        s = s[:-4]
    if not s or len(s) < 2 or len(s) > 12:
        return False
    if s[0].isdigit():
        return False
    if s.isdigit():
        return False
    # allow letters only
    return all('A' <= ch <= 'Z' for ch in s)


def load_universe_symbols(path: Path, prefer_col: Optional[str] = None) -> List[str]:
    """Load symbols from CSV/TXT universe file.
    Tries to be robust to files that include ranks (1,2,3,...) or multiple columns.

    Selection order:
      1) If prefer_col is provided and exists, use that column.
      2) Try common column names: ['symbol','ticker','code','base','asset','coin'] (case-insensitive).
      3) If still unknown, choose the column with the highest share of probable symbols.
      4) Fallback: parse any tokens and keep those that look like symbols.
    """
    if not path.exists():
        raise FileNotFoundError(f"Universe file not found: {path}")

    # TXT — one symbol per line (ignore non-symbol lines)
    if path.suffix.lower() == ".txt":
        lines = [ln.strip() for ln in path.read_text(encoding="utf-8").splitlines()]
        return [ln for ln in lines if is_probable_symbol(ln)]

    # CSV
    import pandas as pd
    try:
        try:
            df = pd.read_csv(path)
        except pd.errors.EmptyDataError:
            return []
        cols = [c for c in df.columns]
        lower_map = {c.lower(): c for c in cols}

        # 1) preferred
        if prefer_col and prefer_col in cols:
            vals = [str(x).strip() for x in df[prefer_col].tolist()]
            return [v for v in vals if is_probable_symbol(v)]
        if prefer_col and prefer_col.lower() in lower_map:
            c = lower_map[prefer_col.lower()]
            vals = [str(x).strip() for x in df[c].tolist()]
            return [v for v in vals if is_probable_symbol(v)]

        # 2) common names
        candidates = ["symbol","ticker","code","base","asset","coin"]
        for cand in candidates:
            if cand in lower_map:
                c = lower_map[cand]
                vals = [str(x).strip() for x in df[c].tolist()]
                kept = [v for v in vals if is_probable_symbol(v)]
                if kept:
                    return kept

        # 3) choose best-fit column
        best_col = None
        best_score = -1
        for c in cols:
            vals = [str(x).strip() for x in df[c].tolist()]
            score = sum(1 for v in vals if is_probable_symbol(v))
            if score > best_score:
                best_score = score
                best_col = c
        if best_col is not None and best_score > 0:
            vals = [str(x).strip() for x in df[best_col].tolist()]
            return [v for v in vals if is_probable_symbol(v)]

        # 4) fallback: tokenize all cells
        tokens: List[str] = []
        for c in cols:
            vals = [str(x) for x in df[c].tolist()]
            for v in vals:
                for t in v.replace("/",",").replace("|",",").replace(" ",",").split(","):
                    t = t.strip()
                    if t:
                        tokens.append(t)
        return [t for t in tokens if is_probable_symbol(t)]

    except Exception:
        # fallback for non-CSV content
        raw = path.read_text(encoding="utf-8")
        parts = [p.strip() for p in raw.replace("", ",").split(",")]
        return [p for p in parts if is_probable_symbol(p)]


# =========================
# CLI
# =========================

def main():
    p = argparse.ArgumentParser(description="OMG 1.5 debug — batch from universe or single symbol")
    p.add_argument("symbol", nargs="?", help="single symbol (e.g., ADA or ADAUSDT)")
    p.add_argument("--debug", dest="single_debug", action="store_true", help="run single-symbol debug with positional SYMBOL")
    p.add_argument("--universe-file", type=str, default=None, help="path to universe list (CSV/TXT) from universe_selector")
    p.add_argument("--universe-col", type=str, default=None, help="column name in universe file that contains symbols (optional)")
    p.add_argument("--limit-days", type=int, default=180)
    args = p.parse_args()

    if args.single_debug and args.symbol:
        out = debug_cycle_for_symbol(args.symbol, limit_days=args.limit_days)
        print(f"[DEBUG] CSV saved: {out}")
        return

    if args.universe_file:
        uni_path = Path(args.universe_file)
        symbols = load_universe_symbols(uni_path, prefer_col=args.universe_col)
        if not symbols:
            raise RuntimeError(f"Universe is empty or no valid symbols found: {uni_path}")
        print(f"[INFO] Loaded {len(symbols)} candidates from {uni_path}")
        for i, raw in enumerate(symbols, 1):
            pair = resolve_pair(raw)
            if not pair:
                base = raw.strip().upper()
                print(f"  ! skip {base}: NOT_LISTED or NO_SUPPORTED_QUOTE")
                continue
            base = stem_from_symbol(pair).upper()
            print(f"[RUN] {i}/{len(symbols)} {base} — pair={pair} — fetching & generating debug (limit={args.limit_days}) …")
            try:
                out = debug_cycle_for_symbol(pair, limit_days=args.limit_days)
                print(f"  → saved {out}")
            except Exception as e:
                print(f"  ! skip {base}: {e}")
                continue
        print(f"[DONE] All debug CSVs saved under {DATA_DIR.resolve()}")
        return

    p.print_help()


if __name__ == "__main__":
    main()
